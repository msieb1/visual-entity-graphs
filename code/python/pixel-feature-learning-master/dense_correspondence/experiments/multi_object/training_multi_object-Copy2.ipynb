{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Object Experiments\n",
    "\n",
    "Try out a variety of multi-object experiments.\n",
    "\n",
    "- Parameter sweep on descriptor dimension\n",
    "- Parameter sweep on `M_background`\n",
    "- single objects in isolation\n",
    "- single objects + multi-object scenes\n",
    "- single objects + multi-object scenes + synthetic multi-object scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# utils.set_default_cuda_visible_devices()\n",
    "utils.set_cuda_visible_devices([1]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', \"caterpillar_baymax_starbot_all_front_single_only.yaml\")\n",
    "\n",
    "cluttered_dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', \"caterpillar_baymax_starbot_all_front.yaml\")\n",
    "\n",
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'training.yaml')\n",
    "\n",
    "\n",
    "\n",
    "logging_dir = \"code/data_volume/pdc/trained_models/cluttered_scene\"\n",
    "num_iterations = 5000\n",
    "num_image_pairs = 100\n",
    "debug = True\n",
    "\n",
    "TRAIN = True\n",
    "EVALUATE = True\n",
    "\n",
    "\n",
    "# num_image_pairs = 10\n",
    "# num_iterations = 10\n",
    "# d_list = [3,4,5,6]\n",
    "d_list = [3,9,16,32,6]\n",
    "# M_background_list = [0.5, 1.0, 1.5, 2.0]\n",
    "M_background_list = [2.0]\n",
    "\n",
    "\n",
    "\n",
    "network_dict = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train networks on single objects in isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [3]:\n",
    "    for M_background in M_background_list:\n",
    "        # load dataset and training config\n",
    "        dataset_config = utils.getDictFromYamlFilename(isolated_dataset_config_filename)\n",
    "        dataset = SpartanDataset(config=dataset_config)\n",
    "        train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "        name = \"no_cross_object_loss_M_background_%.1f_%d\" %(M_background, d)\n",
    "        print \"training %s\" %(name)\n",
    "        train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "        train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "        train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "        train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "        train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "        \n",
    "        train._config[\"training\"][\"data_type_probabilities\"][\"SINGLE_OBJECT_WITHIN_SCENE\"] = 1.0\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"DIFFERENT_OBJECT\"] = 0.5\n",
    "\n",
    "        train._config[\"loss_function\"][\"M_background\"] = M_background\n",
    "\n",
    "\n",
    "        if TRAIN:\n",
    "            train.run()\n",
    "        print \"finished training descriptor of dimension %d\" %(d)\n",
    "        del train\n",
    "\n",
    "         # now do evaluation\n",
    "        print \"running evaluation on network %s\" %(name)\n",
    "        model_folder = os.path.join(logging_dir, name)\n",
    "        model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "        network_dict[name] = model_folder\n",
    "        \n",
    "        if EVALUATE:\n",
    "            DCE = DenseCorrespondenceEvaluation\n",
    "            DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "                                          save_folder_name=\"analysis_isolated_scene\")\n",
    "            \n",
    "            cluttered_dataset_config = utils.getDictFromYamlFilename(cluttered_dataset_config_filename)\n",
    "            cluttered_dataset = SpartanDataset(config=cluttered_dataset_config)\n",
    "            DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "                                          save_folder_name=\"analysis_cluttered_scene\",\n",
    "                                         dataset=cluttered_dataset)\n",
    "            \n",
    "        print \"finished running evaluation on network %s\" %(name)\n",
    "        \n",
    "        # also evaluate them on cross-scene data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in d_list:\n",
    "    for M_background in M_background_list:\n",
    "        # load dataset and training config\n",
    "        dataset_config = utils.getDictFromYamlFilename(isolated_dataset_config_filename)\n",
    "        dataset = SpartanDataset(config=dataset_config)\n",
    "        train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "        name = \"multi_object_isolated_M_background_%.1f_%d\" %(M_background, d)\n",
    "        print \"training %s\" %(name)\n",
    "        train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "        train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "        train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "        train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "        train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "        \n",
    "        train._config[\"training\"][\"data_type_probabilities\"][\"SINGLE_OBJECT_WITHIN_SCENE\"] = 0.5\n",
    "        train._config[\"training\"][\"data_type_probabilities\"][\"DIFFERENT_OBJECT\"] = 0.5\n",
    "        \n",
    "        train._config[\"loss_function\"][\"M_background\"] = M_background\n",
    "\n",
    "\n",
    "        if TRAIN:\n",
    "            train.run()\n",
    "        print \"finished training descriptor of dimension %d\" %(d)\n",
    "        del train\n",
    "\n",
    "         # now do evaluation\n",
    "        print \"running evaluation on network %s\" %(name)\n",
    "        model_folder = os.path.join(logging_dir, name)\n",
    "        model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "        network_dict[name] = model_folder\n",
    "        \n",
    "        if EVALUATE:\n",
    "            DCE = DenseCorrespondenceEvaluation\n",
    "            DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "                                          save_folder_name=\"analysis_isolated_scene\")\n",
    "            \n",
    "            cluttered_dataset_config = utils.getDictFromYamlFilename(cluttered_dataset_config_filename)\n",
    "            cluttered_dataset = SpartanDataset(config=cluttered_dataset_config)\n",
    "            DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "                                          save_folder_name=\"analysis_cluttered_scene\",\n",
    "                                         dataset=cluttered_dataset)\n",
    "            \n",
    "        print \"finished running evaluation on network %s\" %(name)\n",
    "        \n",
    "        # also evaluate them on cross-scene data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Networks with Multi-Object dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in d_list:\n",
    "#     for M_background in M_background_list:\n",
    "#         # load dataset and training config\n",
    "#         dataset_config = utils.getDictFromYamlFilename(cluttered_dataset_config_filename)\n",
    "#         dataset = SpartanDataset(config=dataset_config)\n",
    "#         train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "#         name = \"multi_object_cluttered_M_background_%.1f_%d\" %(M_background, d)\n",
    "#         print \"training %s\" %(name)\n",
    "#         train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "#         train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "#         train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "#         train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "#         train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "#         train._config[\"training\"][\"M_background\"] = M_background\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"SINGLE_OBJECT_WITHIN_SCENE\"] = 0.5\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"DIFFERENT_OBJECT\"] = 0.25\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"MULTI_OBJECT\"] = 0.25\n",
    "        \n",
    "\n",
    "\n",
    "#         if TRAIN:\n",
    "#             train.run()\n",
    "#         print \"finished training descriptor of dimension %d\" %(d)\n",
    "        \n",
    "#         del train\n",
    "\n",
    "#          # now do evaluation\n",
    "#         print \"running evaluation on network %s\" %(name)\n",
    "#         model_folder = os.path.join(logging_dir, name)\n",
    "#         model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "#         network_dict[name] = model_folder\n",
    "#         if EVALUATE:\n",
    "#             DCE = DenseCorrespondenceEvaluation\n",
    "#             DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "#                                           save_folder_name=\"analysis_cluttered_scene\", dataset=dataset)\n",
    "            \n",
    "#             isolated_dataset_config = utils.getDictFromYamlFilename(isolated_dataset_config_filename)\n",
    "#             isolated_dataset = SpartanDataset(config=cluttered_dataset_config)\n",
    "#             DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "#                                           save_folder_name=\"analysis_isolated_scene\", dataset=isolated_dataset)\n",
    "            \n",
    "#         print \"finished running evaluation on network %s\" %(name)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Object Cluttered with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in d_list:\n",
    "#     for M_background in M_background_list:\n",
    "#         # load dataset and training config\n",
    "#         dataset_config = utils.getDictFromYamlFilename(cluttered_dataset_config_filename)\n",
    "#         dataset = SpartanDataset(config=dataset_config)\n",
    "#         train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "#         name = \"multi_object_cluttered_sythetic_M_background_%.1f_%d\" %(M_background, d)\n",
    "#         print \"training %s\" %(name)\n",
    "#         train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "#         train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "#         train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "#         train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "#         train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "#         train._config[\"training\"][\"M_background\"] = M_background\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"SINGLE_OBJECT_WITHIN_SCENE\"] = 0.5\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"DIFFERENT_OBJECT\"] = 0.25\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"MULTI_OBJECT\"] = 0.25/2\n",
    "#         train._config[\"training\"][\"data_type_probabilities\"][\"SYNTHETIC_MULTI_OBJECT\"] = 0.25/2\n",
    "        \n",
    "\n",
    "\n",
    "#         if TRAIN:\n",
    "#             train.run()\n",
    "#         print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    "#          # now do evaluation\n",
    "#         print \"running evaluation on network %s\" %(name)\n",
    "#         model_folder = os.path.join(logging_dir, name)\n",
    "#         model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "#         network_dict[name] = model_folder\n",
    "#         if EVALUATE:\n",
    "#             DCE = DenseCorrespondenceEvaluation\n",
    "#             isolated_dataset_config = utils.getDictFromYamlFilename(isolated_dataset_config_filename)\n",
    "#             dataset = SpartanDataset(config=isolated_dataset_config)\n",
    "#             DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "#                                           save_folder_name=\"analysis_isolated_scene\", dataset=dataset)\n",
    "            \n",
    "#             cluttered_dataset_config = utils.getDictFromYamlFilename(cluttered_dataset_config_filename)\n",
    "#             cluttered_dataset = SpartanDataset(config=cluttered_dataset_config)\n",
    "#             DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs, \n",
    "#                                           save_folder_name=\"analysis_cluttered_scene\",\n",
    "#                                          dataset=cluttered_dataset)\n",
    "            \n",
    "#         print \"finished running evaluation on network %s\" %(name)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
