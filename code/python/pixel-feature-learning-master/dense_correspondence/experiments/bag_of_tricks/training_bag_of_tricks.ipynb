{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Tricks Experiment\n",
    "\n",
    "Analyze the effects of our different \"tricks\".\n",
    "\n",
    "1. Sample matches off mask\n",
    "2. Scale by hard negatives\n",
    "3. L2 pixel loss on matches\n",
    "\n",
    "We will compare standard network, networks missing one trick only, and a network without any tricks (i.e same as Tanner Schmidt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# utils.set_default_cuda_visible_devices()\n",
    "utils.set_cuda_visible_devices([0]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', \"caterpillar_baymax_starbot_all_front_single_only.yaml\")\n",
    "\n",
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'training.yaml')\n",
    "\n",
    "\n",
    "\n",
    "logging_dir = \"code/data_volume/pdc/trained_models/trick_analysis\"\n",
    "num_iterations = 3500\n",
    "num_image_pairs = 100\n",
    "debug = False\n",
    "\n",
    "TRAIN = True\n",
    "EVALUATE = True\n",
    "\n",
    "\n",
    "# num_image_pairs = 10\n",
    "# num_iterations = 10\n",
    "\n",
    "d = 3\n",
    "\n",
    "network_dict = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "\n",
    "\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "name = \"standard_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With L2 on masked non_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "name = \"l2_masked_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "train._config[\"loss_function\"][\"use_l2_pixel_loss_on_masked_non_matches\"] = True\n",
    "\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dont scale by hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "name = \"dont_scale_hard_negatives_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "train._config[\"loss_function\"][\"scale_by_hard_negatives\"] = False\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dont sample off mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "name = \"dont_sample_from_mask_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "train._config[\"training\"][\"sample_matches_only_off_mask\"] = False\n",
    "train._config[\"training\"][\"use_image_b_mask_inv\"] = False\n",
    "train._config[\"training\"][\"fraction_masked_non_matches\"] = 0.01\n",
    "train._config[\"training\"][\"fraction_background_non_matches\"] = 0.99\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "name = \"no_tricks_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "train._config[\"loss_function\"][\"scale_by_hard_negatives\"] = False\n",
    "train._config[\"loss_function\"][\"use_l2_pixel_loss_on_masked_non_matches\"] = False\n",
    "train._config[\"training\"][\"sample_matches_only_off_mask\"] = False\n",
    "\n",
    "train._config[\"training\"][\"use_image_b_mask_inv\"] = False\n",
    "train._config[\"training\"][\"fraction_masked_non_matches\"] = 0.01\n",
    "train._config[\"training\"][\"fraction_background_non_matches\"] = 0.99\n",
    "\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 and dont scale hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "name = \"l2_dont_scale_hard_negatives_run_2_%d\" %(d)\n",
    "print \"training %s\" %(name)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = name\n",
    "train._config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "train._config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "\n",
    "train._config[\"loss_function\"][\"scale_by_hard_negatives\"] = False\n",
    "train._config[\"loss_function\"][\"use_l2_pixel_loss_on_masked_non_matches\"] = True\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "print \"finished training descriptor of dimension %d\" %(d)\n",
    "\n",
    " # now do evaluation\n",
    "print \"running evaluation on network %s\" %(name)\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "network_dict[name] = model_folder\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "print \"finished running evaluation on network %s\" %(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
