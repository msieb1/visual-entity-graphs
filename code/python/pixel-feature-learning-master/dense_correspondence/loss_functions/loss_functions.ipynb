{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "This document outlines a variety of different loss functions that we have discussed.\n",
    "\n",
    "## Notation\n",
    "We follow the notation in Schmidt et. al. as closely as possible\n",
    "\n",
    "- $D(I_a, I_b, u_a, u_b)$ is the L2 norm between descriptor of image $I_a$ at pixel $u_a$ and the descriptor of image $I_b$ at pixel $u_b$. \n",
    "- $\\Delta(u, u')$ is the L2 norm in pixel space between location $u$ and location $u'$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Non-Match Loss\n",
    "\n",
    "Randomly sample lots of background pixels, call them $U_b$. Then the loss is\n",
    "\n",
    "$$ loss = \\sum_{u_b \\in U_b} \\min\\left( M - D(I_a, u_a, I_b, u_b), 0  \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function to target \"best match\"\n",
    "\n",
    "One task that we are particularly interested in is given a pixel $u_a$ in image $I_a$, find the corresponding pixel $u_b^* = g(I_b, u_a)$. The best-match pixel $u_b'$ in image $I_b$ can be found by computing\n",
    "\n",
    "$$ u_b' = \\arg \\min_{u_b} D(I_a,u_a,I_b,u_b)$$\n",
    "\n",
    "Consider the non-match loss given by\n",
    "\n",
    "$$ l = \\sum_{u_b \\in I_b} \\min(\\Delta(u_b, u_b^*), M_p) \\cdot \\min\\left( M_d - \\frac{D(I_a, u_a, I_b, u_b)}{D(I_a, u_a, I_b, u_b^*)}, 0  \\right) $$\n",
    "\n",
    "Reasonable settings could be\n",
    "\n",
    "$$ M_p = 100, M_b = 1.5$$\n",
    "\n",
    "The idea is to penalize points that are within a fraction $M_b$ of l2 norm in descrptor space of the \"true match\" $u_b^*$. We also want to penalize more heavily points that are further away in pixel space.\n",
    "\n",
    "We could also \n",
    "\n",
    "### Variations\n",
    "There are multiple options for the second term in the above sum. A few options are listed below. It's unclear to me what the tradeoffs between these different fomulations are. Tanner et. al. uses a formulation like (2), while some of the other papers with triplet loss use something more similar to (1). \n",
    "\n",
    "1. $ \\min\\left( M - \\frac{D(I_a, u_a, I_b, u_b)}{D(I_a, u_a, I_b, u_b^*)}, 0  \\right)$\n",
    "2. $\\min\\left( M - D(I_a, u_a, I_b, u_b), 0  \\right)$\n",
    "3. $\\min\\left( M \\cdot D(I_a, u_a, I_b, u_b^*) - D(I_a, u_a, I_b, u_b), 0  \\right)$\n",
    "\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "If we implement the above over the \"entire\" image $I_b$ then this would be prohibitively expensive since for each choice of $u_a$ we would have to do the norm-diff over the entire image. One option is to heavily down-sample the number the masked image. Let $\\Gamma_b$ be the downsampled masked image. Then just sum over those pixels.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match-loss\n",
    "\n",
    "For matches we have simply:\n",
    "\n",
    "$$ loss =D(I_a, u_a, I_b, u_b)^2 $$\n",
    "\n",
    "This next mini section addresses whether or not we should square D or not.\n",
    "\n",
    "### L2 squared or not L2 squared?\n",
    "\n",
    "Consider three points, $A$, $B$, $C$ that should all be matches with each other.  Consider the L2 norms between them, call them $AB$, $BC$, and $CA$.\n",
    "\n",
    "If L2 is not squared, the these two situations have the same cost:\n",
    "\n",
    "$AB = BC = CA = 5 \\rightarrow \\sum(\\cdot) = 15$\n",
    "\n",
    "$AB = BC = 1, CA = 13 \\rightarrow \\sum(\\cdot) = 15$\n",
    "\n",
    "Whereas is L2 is squared, then the situation is much different:\n",
    "\n",
    "$AB = BC = CA = 5 \\rightarrow \\sum(\\cdot)^2 = 75$\n",
    "\n",
    "$AB = BC = 1, CA = 13 \\rightarrow \\sum(\\cdot)^2 = 171$\n",
    "\n",
    "#### Plotting the match loss\n",
    "\n",
    "It is dead simple but let's plot the match loss as a function of D:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "y = x**2\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Match loss\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two different types of non-match loss\n",
    "\n",
    "Consider the loss function for non-matches verbatim from Schmidt et al 2017:\n",
    "\n",
    "$$ loss = \\max(0, M - D(I_a, u_a, I_b, u_b) )^2 $$\n",
    "\n",
    "And consider the slight variation we have been using that performs approximately the same:\n",
    "\n",
    "$$ loss = \\max(0, M - D(I_a, u_a, I_b, u_b)^2 ) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's plot the Schmidt et al verbatim non-match-loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M = 0.5\n",
    "y = M - x\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Non-match Loss - Hadsell et al verbatim\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's plot the variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M = 0.5\n",
    "y = M - x**2\n",
    "y = np.where(y>0,y,0)\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Non-match Loss - variation\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = torch.from_numpy(np.arange(-10,10,.001))\n",
    "M = 0.5\n",
    "y = -torch.tanh(x)+1\n",
    "#y = .where(y>0,y,0)\n",
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Tanh version\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = torch.from_numpy(np.arange(-10,10,.001))\n",
    "M = 0.5\n",
    "y = -torch.sigmoid(x-1)+1\n",
    "#y = .where(y>0,y,0)\n",
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Sigmoid version\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could also consider not squared L2 norm for the backgroud non-matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,2,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"masked non match\")\n",
    "x = np.arange(0,2,.001)\n",
    "M_background = 2.0\n",
    "y = (M_background - x)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"background non match\")\n",
    "plt.title(\"Non-match Loss - VARIATION 1\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"masked non match\")\n",
    "x = np.arange(0,1,.001)\n",
    "M_background = 1.0\n",
    "y = (M_background - x)*(M_masked/M_background)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"background non match\")\n",
    "plt.title(\"Non-match Loss - VARIATION 2\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x**2\n",
    "y = np.where(y>0,y,0)\n",
    "plt.plot(x,y,label=\"masked non match\")\n",
    "x = np.arange(0,1,.001)\n",
    "M_background = 1.0\n",
    "y = (M_background - x)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"background non match\")\n",
    "plt.title(\"Non-match Loss - VARIATION 2\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,0.5,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x**2\n",
    "y = np.where(y>0,y,0)\n",
    "plt.plot(x,y,label=\"first part\")\n",
    "x = np.arange(0.5,1.0,.001)\n",
    "M_background = 1.0\n",
    "y = (M_background - x)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"second part\")\n",
    "plt.title(\"Non-match Loss - VARIATION 2\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"masked non match\")\n",
    "x = np.arange(0,1,.001)\n",
    "M_background = 0.5\n",
    "y = (M_background - x)*(M_masked/M_background)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y\n",
    "plt.plot(x,y,label=\"background non match\")\n",
    "plt.title(\"Non-match Loss - VARIATION 3\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,1,.001)\n",
    "M_masked = 0.5\n",
    "y = M_masked - x\n",
    "y = np.where(y>0,y,0)\n",
    "y = y**2\n",
    "plt.plot(x,y,label=\"masked non match\")\n",
    "x = np.arange(0,1,.001)\n",
    "M_background = 1.0\n",
    "y = (M_background - x)*(M_masked/M_background)\n",
    "y = np.where(y>0,y,0)\n",
    "y = y\n",
    "plt.plot(x,y,label=\"background non match\")\n",
    "plt.title(\"Non-match Loss - VARIATION 3\")\n",
    "plt.xlabel(\"D\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
